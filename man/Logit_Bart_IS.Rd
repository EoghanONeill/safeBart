% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Logit_BART_IS.R, R/Logit_BART_IS_ITEs.R
\name{Logit_Bart_IS}
\alias{Logit_Bart_IS}
\title{Parallel Logit Bayesian Additive Regression Trees}
\usage{
Logit_Bart_IS(
  seed,
  y,
  original_datamat,
  ztrain,
  pihat_train,
  test_datamat = matrix(0, 0, 0),
  test_pihat = matrix(0, 0, 0),
  lambda = 0.45,
  num_models = 1000,
  num_trees = 5,
  beta_par = 1,
  ncores = 1,
  outsamppreds = 1,
  nu = 3,
  a = 3,
  sigquant = 0.9,
  valid_trees = 1,
  tree_prior = 0,
  imp_sampler = 0,
  alpha_BART = 0.95,
  beta_BART = 2,
  s_t_hyperprior = 1,
  p_s_t = 0.5,
  a_s_t = 1,
  b_s_t = 3,
  lambda_poisson = 10,
  fast_approx = 0,
  PIT_propensity = 0,
  l_quant = 0.025,
  u_quant = 0.975,
  root_alg_precision = 1e-05,
  maxit = 300,
  eps_f = 1e-08,
  eps_g = 1e-05,
  num_iter = 1000,
  include_cate_intervals = 0
)

Logit_Bart_IS(
  seed,
  y,
  original_datamat,
  ztrain,
  pihat_train,
  test_datamat = matrix(0, 0, 0),
  test_pihat = matrix(0, 0, 0),
  lambda = 0.45,
  num_models = 1000,
  num_trees = 5,
  beta_par = 1,
  ncores = 1,
  outsamppreds = 1,
  nu = 3,
  a = 3,
  sigquant = 0.9,
  valid_trees = 1,
  tree_prior = 0,
  imp_sampler = 0,
  alpha_BART = 0.95,
  beta_BART = 2,
  s_t_hyperprior = 1,
  p_s_t = 0.5,
  a_s_t = 1,
  b_s_t = 3,
  lambda_poisson = 10,
  fast_approx = 0,
  PIT_propensity = 0,
  l_quant = 0.025,
  u_quant = 0.975,
  root_alg_precision = 1e-05,
  maxit = 300,
  eps_f = 1e-08,
  eps_g = 1e-05,
  num_iter = 1000,
  include_cate_intervals = 0
)
}
\arguments{
\item{seed}{The seed for random number generation.}

\item{y}{The training data vector of outcomes. This must be a vector of zeros and ones.}

\item{original_datamat}{The original test data. This matrix must have the same number of columns (variables) as the training data. Currently all variables must be continuous. The test data does not need to be transformed before being entered to this function.}

\item{lambda}{A real number between 0 and 1 that determines the splitting probability in the prior (which is used as the importance sampler of tree models). Quadrianto and Ghahramani (2015) recommend a value less than 0.5 .}

\item{num_trees}{The number of trees to be sampled.}

\item{beta_par}{The power to which the likelihood is to be raised. For BMA, set beta_par=1.}

\item{ncores}{The number of cores to be used in parallelization.}

\item{valid_trees}{If equal to 1, restrict splits so that they describe feasible/valid partitions. e.g. can't have a rule x1<0.75 as the splitting rule for the left child node of a parent node with the splitting rule x1<0.5}

\item{tree_prior}{1 = BART prior, 2= spike-and-tree, otherwise default prior by Novi and Quandrianto}

\item{imp_sampler}{Importance sampler for trees. 1 = BART prior, 2= spike-and-tree, otherwise default prior by Novi and Quandrianto}

\item{alpha_BART}{The alpha parameter for the standard BART prior.}

\item{beta_BART}{The beta parameter for the standard BART prior.}

\item{fast_approx}{If equal to 1, use an approximate BIC weighted average and do not invert matrices for each model (should also use SVD).}

\item{maxit}{Maximum number of iterations for the quasi-Newton algorithm that finds the MAP estimate for each model (required for Laplace approximation).}

\item{eps_f}{Parameter for MAP algorithm stopping criterion. Iteration stops if |f-f'|/|f|<eps_f, where f and f' are the current and previous value of the objective function (negative log likelihood) respectively.}

\item{eps_g}{Parameter for MAP algorithm stopping criterion. Iteration stops if ||g|| < eps_g * max(1, ||beta||), where beta is the current coefficient vector and g is the gradient.}

\item{num_cats}{The number of possible values for the outcome variable.}

\item{alpha_parameters}{Vector of prior parameters.}
}
\value{
A matrix of probabilities with the number of rows equl to the number of test observations and the number of columns equal to the number of possible outcome categories.

A matrix of probabilities with the number of rows equl to the number of test observations and the number of columns equal to the number of possible outcome categories.
}
\description{
A parallelized implementation of Logit-BART-IS

A parallelized implementation of Logit-BART-IS
}
\examples{
beta_par <- 0.5

N <- 100
p<- 5
set.seed(100)

epsilon <- rnorm(N)

xcov <- matrix(runif(N*p), nrow=N)

y <- sin(pi*xcov[,1]*xcov[,2]) + 20*(xcov[,3]-0.5)^2+10*xcov[,4]+5*xcov[,5]+epsilon
# <- rep(1,N) + epsilon

epsilontest <- rnorm(N)

xcovtest <- matrix(runif(N*p), nrow=N)
ytest <- sin(pi*xcovtest[,1]*xcovtest[,2]) + 20*(xcovtest[,3]-0.5)^2+10*xcovtest[,4]+5*xcovtest[,5]+epsilontest
#ytest <- rep(1,N) + epsilontest




Num_split_vars <- 10

lambda <- 0.45
Num_models <- 10000
num_trees1 <- 5

seed1 <- 42
ncores <- 7



examplepreds1 <- safeBart_parallel(seed1,
                                   y, xcov,xcovtest,
                                   lambda=0.45,
                                   num_models=Num_models,
                                   num_trees=num_trees1,
                                   beta_par=beta_par,
                                   ncores=ncores,
                                   outsamppreds=1,
                                   nu=3,
                                   a=3,
                                   sigquant=0.9,
                                   valid_trees=1)

cbind(examplepreds1,ytest )
beta_par <- 0.5

N <- 100
p<- 5
set.seed(100)

epsilon <- rnorm(N)

xcov <- matrix(runif(N*p), nrow=N)

y <- sin(pi*xcov[,1]*xcov[,2]) + 20*(xcov[,3]-0.5)^2+10*xcov[,4]+5*xcov[,5]+epsilon
# <- rep(1,N) + epsilon

epsilontest <- rnorm(N)

xcovtest <- matrix(runif(N*p), nrow=N)
ytest <- sin(pi*xcovtest[,1]*xcovtest[,2]) + 20*(xcovtest[,3]-0.5)^2+10*xcovtest[,4]+5*xcovtest[,5]+epsilontest
#ytest <- rep(1,N) + epsilontest




Num_split_vars <- 10

lambda <- 0.45
Num_models <- 10000
num_trees1 <- 5

seed1 <- 42
ncores <- 7



examplepreds1 <- safeBart_parallel(seed1,
                                   y, xcov,xcovtest,
                                   lambda=0.45,
                                   num_models=Num_models,
                                   num_trees=num_trees1,
                                   beta_par=beta_par,
                                   ncores=ncores,
                                   outsamppreds=1,
                                   nu=3,
                                   a=3,
                                   sigquant=0.9,
                                   valid_trees=1)

cbind(examplepreds1,ytest )
}
